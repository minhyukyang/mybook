# 제인 오스틴(Jane Austen) 작품 분석 {#tidyausten}

제인 오스틴(Jane Austen)이 탈고해 출판한 소설 여섯 개를 [janeaustenr](https://cran.r-project.org/package=janeaustenr) 패키지 에서 가져온 다음 tidy 형식으로 변형해 보자. 

- janeaustenr 패키지는 텍스트를 1줄당 1행(one-row-per-line) 형식으로 제공
- `mutate()`를 사용해 `linenumber` 수에 해당하는 만큼을 주석으로 처리함으로써 원래 줄 형식을 추적하는데 사용
- `chapter`를 사용해 모든 장이 어디부터 나오는지 찾아낸다

```{r original_books}
library(janeaustenr)
library(dplyr)
library(stringr)

original_books <- austen_books() %>%
  group_by(book) %>%
  mutate(linenumber = row_number(),
         chapter = cumsum(str_detect(text, 
                                     regex("^chapter [\\divxlc]",
                                           ignore_case = TRUE)))) %>%
  ungroup()

original_books
```

이것을 tidy 데이터셋으로 사용하려면 `unnest_tokens()` 함수를 사용해 **1행당 1토큰(one-token-per-row)** 형식으로 구성해야 한다.

```{r tidy_books_raw, dependson = "original_books"}
library(tidytext)
tidy_books <- original_books %>%
  unnest_tokens(word, text)

tidy_books
```

이 함수는 [tokenizers](https://github.com/ropensci/tokenizers)를 사용해 원래 데이터 프레임에 있는 텍스트의 각 행을 토큰으로 분리한다. 기본 토큰화는 단어에 대한 것이지만 다른 옵션을 사용하면 문자, 엔그램, 문장, 줄, 단락 단위로 토큰호하 할 수 있고, 또는 정규 표혀노식 패턴을 사용해서 분리할 수 있다.

불용어(stop words)는 분석에 유용하지 않은 단어들을 말하며, 일반적으로 영어의 'the', 'of', 'to' 등과 같은 매우 전형적인 단어를 말한다. `anti_join()`을 사용해 불용어를 제거할 수 있다. 이 때, 사용되는 불용어는 `stop_words`를 사용한다.

```{r tidy_books, dependson = "tidy_books_raw"}
data(stop_words)

tidy_books <- tidy_books %>%
  anti_join(stop_words)
```

tidytext 패키지의 `stop_words` 데이터셋에는 3개의 불용어 용어집(lexicon)이 들어있다. 지금처럼 모두 함께 사용할 수도 있고, 특정 분석에 더 적합한 경우 `filter()`를 사용해 1개 불용어 집합만 사용할 수도 있다.

또한, dplyr의 `count()`를 사용해 모든 도서에서 가장 흔하게 나오는 단어를 찾을 수 있다.

```{r dependson = "tidy_books"}
tidy_books %>%
  count(word, sort = TRUE) 
```

단어 카운트(word count) 결과는 tidy data frame에 저장되었기 때문에 아래처럼 ggplot2 패키지로 직접 연결(pipe)할 수 있습니다
(Figure \@ref(fig:plotcount)).

```{r plotcount, dependson = "tidy_books", fig.cap="The most common words in Jane Austen's novels"}
library(ggplot2)

tidy_books %>%
  count(word, sort = TRUE) %>%
  filter(n > 600) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(n, word)) +
  geom_col() +
  labs(y = NULL)
```

## Ref.

1. [janeaustenr](https://cran.r-project.org/package=janeaustenr)
2. [tokenizers](https://github.com/ropensci/tokenizers)